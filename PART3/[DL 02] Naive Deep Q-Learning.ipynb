{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('..') # add project root to the python path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "from src.part3.MLP import MultiLayerPerceptron as MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 새로운 환경 `CartPole-v1`\n",
    "\n",
    "이번 실습에서는 새로운 환경을 가지고 여러분들의 강화학습 지식을 \"강화\" 해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"https://www.youtube.com/embed/37uDD7HFf6U\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x12f826a90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cartpole_link = '37uDD7HFf6U'\n",
    "YouTubeVideo(cartpole_link, width=800, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `CartPole-v1` MDP 알아보기\n",
    "\n",
    "* openai gym `cartpole.py`의 내용을 참조하여 작성되었습니다. 원문은 [여기](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py)에서 찾아보실 수 있습니다.\n",
    "<br>\n",
    "\n",
    "### `CartPole-v1`  MDP에 적용되는 물리법칙\n",
    "1. 카트는 마찰이 없는 평면의 트랙위에서 움직인다.\n",
    "2. 전체 시스템에는 중력이 작용한다. 따라서, 가만히 카트를 두면 막대 (pole)가 떨어진다.\n",
    "\n",
    "### 인간의 직관을 이용한 솔루션\n",
    "> ???: 적당히 왼쪽 오른쪽으로 움직여 주면 되겠군...\n",
    "\n",
    "\n",
    "### MDP의 목적\n",
    "`CartPole-v1` MDP의 Goal은 카트에 달린 막대를 최대한 오랫동안 __세워두는__ 것입니다. __'세워둔다'__ 의 정의는 막대가 수직으로 부터 15&deg; 이내에 있게 유지하는 것입니다. 추가적으로 평면의 중심에서 2.4 unit 이상 멀어지면 떨어진것으로 간주됩니다.\n",
    "\n",
    "### 상태 $s$, 행동 $a$, 보상 $r$, 감소율 $\\gamma$\n",
    "\n",
    ">`CartPole-v1` MDP 는 다음과 같은 4-dimensional 상태 $s$ 를 가집니다.\n",
    "1. x : 카트의 위치\n",
    "2. θ : 막대의 수직 각도\n",
    "3. dx/dt : 카트의 속도\n",
    "4. dθ/dt : 막대의 각속도\n",
    "\n",
    ">`CartPole-v1` MDP 는 다음과 같은 1-dimensional 상태 $a$ 를 가집니다. <br>\n",
    "+1, -1 으로 카트에 힘을 가하기. (좌/우로 1의 힘을 가함)\n",
    "\n",
    ">`CartPole-v1` MDP 는 매 1tick `step()` 마다 1.0 의 보상 $r$ 을 받습니다.\n",
    "\n",
    ">`CartPole-v1` MDP 감소율 $\\gamma$ 이 1.0 입니다.\n",
    "\n",
    "### `CartPole-v1` MDP 를 \"풀었다\" ?\n",
    "`CartPole-v1` MDP에서 100회 연속적으로 195.0의 cumulative reward 를 얻으면, `CartPole-v1` MDP를 \"풀었다\"라고 정의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랜덤 액션으로 'CartPole-v1' 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"https://www.youtube.com/embed/4fR836k_T40\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x12f8436d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cartpole_link = '4fR836k_T40'\n",
    "YouTubeVideo(cartpole_link, width=800, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junyoungpark/.pyenv/versions/3.7.5/envs/torch/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "/Users/junyoungpark/.pyenv/versions/3.7.5/envs/torch/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    #env.render() # rendering the outcomes\n",
    "    env.step(env.action_space.sample()) # take a random action\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상태공간 $\\mathcal{S}$ 및 행동공간 $\\mathcal{A}$ 확인하기\n",
    "\n",
    "OpenAI gym의 환경이니 모름지기 표준화된 interface를 제공하겠죠? 한번 상태공간과 행동공간에 대해서 확인해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state space dimension: 4\n",
      "action space dimension: 2\n"
     ]
    }
   ],
   "source": [
    "s_dim = env.observation_space.shape[0]\n",
    "a_dim = env.action_space.n\n",
    "\n",
    "print(\"state space dimension: {}\".format(s_dim))\n",
    "print(\"action space dimension: {}\".format(a_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-Network (DQN): 퍼스트 컨택트\n",
    "\n",
    "드디어 <파트 3. 함수 근사기법>에서 배운것들이 강화학습과에 처음으로 사용되는 순간입니다! 딥러닝을 이용해서 Q-Learning을 진행해볼까요?\n",
    "\n",
    "일단 Function approximation을 활용한 Q-Learning의 의사 코드를 살펴봅시다.\n",
    "\n",
    "<img src=\"./images/ql_fa.png\" width=\"70%\" height=\"40%\" title=\"q_learning_with_fa\" alt=\"ql_fa\"></img>\n",
    "\n",
    "비교를 위해서 Funciton approximation을 활용하지 않는 경우도 확인 해볼까요?\n",
    "\n",
    "<img src=\"../part2/images/q_learning.png\" width=\"70%\" height=\"40%\" title=\"q_learning_with_fa\" alt=\"ql\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaiveDQN 을 구현해봅시다!\n",
    "\n",
    "파이토치 문법에 익숙해질겸 한번 간단한 DQN을 만들어볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveDQN(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 state_dim: int,\n",
    "                 action_dim: int,\n",
    "                 qnet: nn.Module,\n",
    "                 lr: float,\n",
    "                 gamma: float,\n",
    "                 epsilon: float):\n",
    "        super(NaiveDQN, self).__init__()\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.qnet = qnet\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.opt = torch.optim.Adam(params=self.qnet.parameters(), lr=lr)\n",
    "        self.register_buffer('epsilon', torch.ones(1) * epsilon)\n",
    "\n",
    "        self.criteria = nn.MSELoss()\n",
    "\n",
    "    def get_action(self, state):\n",
    "        qs = self.qnet(state)  # Notice that qs is 2d tensor [batch x action]\n",
    "\n",
    "        if self.train:  # epsilon-greedy policy\n",
    "            prob = np.random.uniform(0.0, 1.0, 1)\n",
    "            if torch.from_numpy(prob).float() <= self.epsilon:  # random\n",
    "                action = np.random.choice(range(self.action_dim))\n",
    "            else:  # greedy\n",
    "                action = qs.argmax(dim=-1)\n",
    "                \n",
    "        else:  # greedy policy\n",
    "            action = qs.argmax(dim=-1)\n",
    "        return int(action)\n",
    "\n",
    "    def update_sample(self, state, action, reward, next_state, done):\n",
    "        s, a, r, ns = state, action, reward, next_state\n",
    "        # Q-Learning target\n",
    "        q_max, _ = self.qnet(next_state).max(dim=-1)\n",
    "        q_target = r + self.gamma * q_max * (1 - done)\n",
    "\n",
    "        # Don't forget to detach `td_target` from the computational graph\n",
    "        q_target = q_target.detach()\n",
    "\n",
    "        # Or you can follow a better practice as follows:\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            q_max, _ = self.qnet(next_state).max(dim=-1)\n",
    "            q_target = r + self.gamma * q_max * (1 - done)\n",
    "        \"\"\"\n",
    "\n",
    "        loss = self.criteria(self.qnet(s)[0, a], q_target)\n",
    "        self.opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self.opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnet = MLP(input_dim=s_dim,\n",
    "           output_dim=a_dim,\n",
    "           num_neurons=[128],\n",
    "           hidden_act='ReLU',\n",
    "           out_act='Identity')\n",
    "\n",
    "agent = NaiveDQN(state_dim=s_dim,\n",
    "                 action_dim=a_dim,\n",
    "                 qnet=qnet,\n",
    "                 lr=1e-4,\n",
    "                 gamma=1.0,\n",
    "                 epsilon=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training 동안에 모델의 성능을 평가하는 metric을 하나 만들어봅시다.\n",
    "\n",
    "Q-Learning (따라서, DQN도 포함) 은 행동 정책과 평가의 대상인 타겟 정책이 다릅니다. 따라서, 학습 중간에 모델을 평가하기 위해서는 Agent의 Test behaviour를 사용하는 것이 맞겠죠?\n",
    "\n",
    "예를 들어,\n",
    "``` python\n",
    "for i in range(n_eps): # total training loop\n",
    "    while True: # episode loop\n",
    "        ...\n",
    "        action, get sample, update\n",
    "        ...\n",
    "    \n",
    "    if i % test_every == 0:\n",
    "        agent.eval() # set agent to the test mode.\n",
    "        ...\n",
    "        evaluate the agent on the MDP maybe multiple times!\n",
    "        ...\n",
    "        agent.train() # set agent back to the train mode.      \n",
    "```\n",
    "\n",
    "하지만, 이렇게 구현을 하면 모델의 evaluation 에 대한 시간적 비용이 상당히 큰 경우들이 많습니다. 그래서 많은 경우에, 모델의 성능을 평가하기 위해서 여태까지 얻었던 에피소드 리턴 --하나의 에피소드에서 얻은 리워드들의 (감가) 합-- 을 사용합니다. \n",
    "\n",
    "이번 예제에서는 지수 이동평균법으로 모델의 성능변화를 추적해보도록하죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EMAMeter:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 alpha:float = 0.5):\n",
    "        self.s = None\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def update(self, y):        \n",
    "        if self.s is None:\n",
    "            self.s = y\n",
    "        else:\n",
    "            self.s = self.alpha * y + (1-self.alpha) * self.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 || EMA: 47.0 || EPS : tensor([1.])\n",
      "Episode 500 || EMA: 14.76917895158208 || EPS : tensor([0.7046])\n",
      "Episode 1000 || EMA: 11.964059885294855 || EPS : tensor([0.4272])\n",
      "Episode 1500 || EMA: 14.384016599387063 || EPS : tensor([0.2591])\n",
      "Episode 2000 || EMA: 11.708910182458421 || EPS : tensor([0.1571])\n",
      "Episode 2500 || EMA: 21.414071513075253 || EPS : tensor([0.0953])\n",
      "Episode 3000 || EMA: 19.83594722137275 || EPS : tensor([0.0578])\n",
      "Episode 3500 || EMA: 16.06575680638438 || EPS : tensor([0.0350])\n",
      "Episode 4000 || EMA: 29.446456529947696 || EPS : tensor([0.0212])\n",
      "Episode 4500 || EMA: 30.11883754420156 || EPS : tensor([0.0129])\n",
      "Episode 5000 || EMA: 17.15251767455988 || EPS : tensor([0.0078])\n",
      "Episode 5500 || EMA: 17.95705523749909 || EPS : tensor([0.0047])\n",
      "Episode 6000 || EMA: 26.480155795527978 || EPS : tensor([0.0029])\n",
      "Episode 6500 || EMA: 35.194290735829924 || EPS : tensor([0.0017])\n",
      "Episode 7000 || EMA: 50.60013498566879 || EPS : tensor([0.0011])\n",
      "Episode 7500 || EMA: 58.26727588766791 || EPS : tensor([0.0006])\n",
      "Episode 8000 || EMA: 113.62969442976907 || EPS : tensor([0.0004])\n",
      "Episode 8500 || EMA: 14.802258819330023 || EPS : tensor([0.0002])\n",
      "Episode 9000 || EMA: 15.953962468422034 || EPS : tensor([0.0001])\n",
      "Episode 9500 || EMA: 109.14264145998547 || EPS : tensor([8.6570e-05])\n"
     ]
    }
   ],
   "source": [
    "n_eps = 10000\n",
    "print_every = 500\n",
    "ema_factor = 0.5\n",
    "ema = EMAMeter(ema_factor)\n",
    "\n",
    "for ep in range(n_eps):\n",
    "    env.reset()  # restart environment\n",
    "    cum_r = 0\n",
    "    while True:\n",
    "        s = env.state\n",
    "        s = torch.tensor(s).float().view(1, 4)  # convert to torch.tensor\n",
    "        a = agent.get_action(s)\n",
    "        ns, r, done, info = env.step(a)\n",
    "\n",
    "        ns = torch.tensor(ns).float()  # convert to torch.tensor\n",
    "        agent.update_sample(s, a, r, ns, done)\n",
    "        cum_r += r\n",
    "        if done:\n",
    "            ema.update(cum_r)\n",
    "\n",
    "            if ep % print_every == 0:\n",
    "                print(\"Episode {} || EMA: {} || EPS : {}\".format(ep, ema.s, agent.epsilon))\n",
    "\n",
    "            if ep >= 150:\n",
    "                agent.epsilon *= 0.999\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시간이 오래걸릴거에요! 포기하지 마세요 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다른 사람들의 기록은 어떨까?\n",
    "\n",
    "[openai gym 사이트](https://gym.openai.com/envs/CartPole-v0/)에 방문하면 다른 사람들의 기록도 확인해볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오랜날 오랜밤 그댈 훈련했어요.\n",
    "\n",
    "많은 머신러닝 모델 그리고 강화학습 모델은 더욱 그러하듯, 모델의 훈련에 생각보다 많은 시간 및 연산자원이 필요합니다. 그래서 훈련된 모델을 잘 저장하는 것이 필요합니다. 파이토치 모델을 저장하는 법을 알아볼까요?\n",
    "\n",
    "> 모델을 `nn.Module` 을 상속받아서 만들었다고 가정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = './navie_dqn.pt'\n",
    "torch.save(agent.state_dict(), SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('epsilon', tensor([5.2495e-05])),\n",
       "             ('qnet.layers.0.weight',\n",
       "              tensor([[-2.5274e-01, -1.0068e-01, -6.6648e-01, -1.4273e-01],\n",
       "                      [ 6.3685e-03,  1.1984e+00,  1.4588e+00,  1.2057e+00],\n",
       "                      [-7.9896e-01,  1.5624e-01,  5.4470e-01, -1.6938e-01],\n",
       "                      [-4.4573e-02, -3.0556e-01, -1.8010e+00, -5.5101e-01],\n",
       "                      [-6.3286e-01, -2.2097e-01,  1.1782e-01, -3.8638e-01],\n",
       "                      [-7.1657e-01, -3.3559e-01,  6.3424e-01,  5.2899e-01],\n",
       "                      [-2.9158e-01,  1.0486e-01,  4.6626e-01,  4.8948e-03],\n",
       "                      [-7.7268e-01,  1.2427e-01,  3.9761e-01, -4.3084e-01],\n",
       "                      [ 4.8953e-01, -3.7138e-01,  4.8951e-01, -1.5558e-01],\n",
       "                      [-3.5489e-01,  1.9541e-01,  5.6598e-01, -3.2747e-01],\n",
       "                      [-2.5850e-01,  2.2271e-02, -1.2181e-01, -1.8363e-01],\n",
       "                      [-6.6856e-01,  4.2945e-01, -4.1947e-01,  1.1752e-02],\n",
       "                      [-8.8613e-01,  2.4342e-01,  2.7556e-01, -1.5106e-01],\n",
       "                      [-1.1327e+00, -4.9109e-01,  4.4440e-01,  1.1181e-01],\n",
       "                      [-2.1302e-01,  7.9746e-01,  1.7114e+00,  1.1340e+00],\n",
       "                      [-4.1125e-02, -2.3066e-01, -1.3572e-01, -4.2071e-02],\n",
       "                      [-1.6432e-01, -3.4914e-01,  3.6136e-01, -2.6125e-01],\n",
       "                      [ 5.0416e-01, -4.8463e-01, -1.2442e+00, -7.7392e-01],\n",
       "                      [ 8.7478e-02,  7.1535e-01,  1.7291e+00,  1.0625e+00],\n",
       "                      [-2.5386e-01,  1.8020e-01, -3.8648e-01,  3.4629e-01],\n",
       "                      [-6.4514e-01,  1.5716e-01, -4.8180e-02,  1.4021e-01],\n",
       "                      [-4.5624e-01,  7.9707e-03,  4.0237e-01, -1.2257e-01],\n",
       "                      [-5.0100e-01,  2.2681e-01, -1.2583e-01, -1.2320e-01],\n",
       "                      [-2.5099e-01, -1.1872e-02, -1.1767e-01, -8.6048e-02],\n",
       "                      [-6.2496e-01, -2.0600e-01, -1.0459e-01, -4.9232e-01],\n",
       "                      [-4.6662e-01,  3.2273e-02,  4.8839e-01, -1.7274e-01],\n",
       "                      [-1.5707e-01, -3.0799e-01,  3.3868e-01,  2.0816e-01],\n",
       "                      [-2.4717e-01,  1.4629e-01, -9.2950e-02, -4.0518e-01],\n",
       "                      [-2.4071e-01, -1.4769e-01, -2.1676e-01,  1.0029e-01],\n",
       "                      [ 5.7891e-02, -1.7909e-01,  1.8628e-01, -1.7098e-02],\n",
       "                      [-3.5343e-01,  7.6027e-02,  2.4733e-03, -2.5116e-01],\n",
       "                      [ 3.7576e-01,  9.8034e-01,  1.2587e+00,  1.1095e+00],\n",
       "                      [ 6.3896e-01, -1.0383e+00, -1.9851e+00, -2.0152e+00],\n",
       "                      [ 3.5571e-01,  8.7373e-01,  1.1626e+00,  1.2993e+00],\n",
       "                      [-5.8215e-01, -1.9586e-01,  2.2537e-02,  3.5296e-01],\n",
       "                      [-3.7591e-01, -3.1101e-01, -5.7840e-02, -3.6117e-01],\n",
       "                      [-5.0472e-01,  1.6397e-01,  1.2695e-01, -1.5062e-01],\n",
       "                      [-7.8357e-01, -1.7197e-01, -2.6605e-02,  9.7357e-02],\n",
       "                      [-5.8209e-01, -3.9985e-01,  4.6935e-01,  2.6984e-01],\n",
       "                      [-1.3666e-01, -1.0798e-01, -8.0046e-02,  1.8770e-01],\n",
       "                      [-6.0844e-01,  4.0469e-01,  1.6820e-02,  2.8492e-01],\n",
       "                      [-2.2080e-01,  6.7309e-02, -4.2135e-01,  1.2730e-01],\n",
       "                      [-6.8360e-01,  3.3381e-01, -4.2332e-01, -1.6059e-01],\n",
       "                      [-4.9568e-02, -2.2798e-01, -6.2120e-01,  1.2824e-01],\n",
       "                      [-2.8179e-01,  6.4591e-02,  1.9266e-01,  1.6586e-01],\n",
       "                      [-6.5832e-01,  3.1662e-01,  2.9850e-02, -1.6049e-01],\n",
       "                      [ 2.1221e-02,  1.0706e+00,  1.0961e+00,  1.0742e+00],\n",
       "                      [-6.9440e-02, -1.3853e-01, -1.0041e-02,  2.4366e-01],\n",
       "                      [-7.8534e-01,  4.1054e-01, -3.6331e-01, -2.3822e-01],\n",
       "                      [-5.1292e-01, -3.2918e-01, -4.2660e-01,  2.4826e-01],\n",
       "                      [ 3.9943e-01,  9.3431e-01,  1.6921e+00,  8.9760e-01],\n",
       "                      [-6.9400e-01,  3.3940e-01,  2.1287e-01, -2.4512e-01],\n",
       "                      [ 2.5977e-01,  1.0471e+00,  1.4151e+00,  1.1998e+00],\n",
       "                      [ 1.0721e+00, -6.1333e-01, -9.8405e-01, -1.3860e+00],\n",
       "                      [ 1.3817e-01, -1.7452e-01, -3.3949e-01, -1.5293e-03],\n",
       "                      [-6.6154e-01,  3.0565e-01, -1.3869e-01, -1.4089e-01],\n",
       "                      [-3.2425e-01,  2.2958e-02,  2.1984e-01,  1.8816e-01],\n",
       "                      [ 5.4639e-01, -6.6717e-01, -1.5453e+00, -1.1070e+00],\n",
       "                      [-5.9495e-01, -2.8925e-01, -4.4095e-01,  2.0557e-01],\n",
       "                      [-6.1370e-01,  3.1933e-01,  2.0745e-01,  2.3702e-01],\n",
       "                      [ 9.7572e-01, -5.0899e-01, -1.3273e+00, -1.0698e+00],\n",
       "                      [-6.8213e-01,  4.3697e-01, -4.8022e-02, -1.9608e-01],\n",
       "                      [ 1.1545e+00,  3.9999e-01, -1.0704e+00, -4.4756e-01],\n",
       "                      [ 3.0458e-01, -9.5902e-01, -1.4184e+00, -1.3538e+00],\n",
       "                      [-1.3114e-03,  1.1867e+00,  1.1004e+00,  9.5316e-01],\n",
       "                      [-5.0881e-01, -2.9716e-01,  4.3324e-01, -6.0420e-02],\n",
       "                      [-5.6298e-01, -5.6382e-01, -4.5171e-01, -6.1560e-01],\n",
       "                      [-5.9926e-01,  8.1733e-02,  2.4011e-02, -1.5259e-01],\n",
       "                      [ 1.2203e+00, -5.0664e-01, -1.2283e+00, -1.0794e+00],\n",
       "                      [ 2.7576e-01, -8.0613e-01, -1.8308e+00, -1.0563e+00],\n",
       "                      [-2.7118e-01, -7.6258e-02,  9.9550e-02, -6.0600e-02],\n",
       "                      [-4.6010e-01,  8.2420e-02,  3.0057e-01, -4.2645e-01],\n",
       "                      [ 1.2328e+00, -8.0393e-01, -1.1888e+00, -1.3958e+00],\n",
       "                      [-6.5195e-01, -4.1752e-01,  3.8276e-01, -9.8267e-02],\n",
       "                      [-7.2884e-01, -5.9799e-02, -3.6481e-01, -2.5915e-01],\n",
       "                      [-8.6933e-01,  2.0574e-01,  4.3064e-01,  1.2519e-01],\n",
       "                      [-4.3893e-01,  1.8752e-01,  2.5586e-01,  2.2808e-01],\n",
       "                      [-3.0933e-01, -3.1249e-02,  1.3667e-01, -9.2543e-02],\n",
       "                      [-9.1448e-01,  1.1019e-01, -2.1288e-01, -2.8973e-01],\n",
       "                      [-5.4210e-01,  1.8134e-01,  3.2955e-01, -3.1581e-01],\n",
       "                      [-6.8018e-01,  1.6352e-01,  3.5516e-01, -2.2068e-01],\n",
       "                      [-5.7393e-02, -2.3605e-01, -2.9240e-01,  2.4430e-01],\n",
       "                      [-2.9867e-01,  9.8007e-02,  4.1597e-02, -4.0590e-01],\n",
       "                      [-1.8992e-01,  2.0997e-01, -3.2839e-02,  6.4192e-02],\n",
       "                      [-7.7801e-01, -5.3990e-01, -4.6958e-01, -4.2892e-01],\n",
       "                      [-7.7751e-01,  1.9776e-01,  2.7270e-01, -8.9519e-02],\n",
       "                      [-5.1281e-01, -3.1992e-01, -1.8180e-02, -4.0125e-01],\n",
       "                      [-8.2186e-01,  4.0946e-01, -3.3423e-01,  5.1428e-02],\n",
       "                      [-9.9534e-01,  1.0573e-01,  7.0803e-01, -4.2278e-01],\n",
       "                      [ 3.4937e-01,  6.7653e-01,  2.0432e+00,  9.9519e-01],\n",
       "                      [-7.4545e-01,  5.0722e-01, -4.8586e-01,  7.3090e-02],\n",
       "                      [-1.0733e-01, -6.1685e-01, -5.2684e-01,  2.6111e-01],\n",
       "                      [-4.2064e-01, -8.0237e-02, -9.9222e-02,  2.9613e-01],\n",
       "                      [-9.3641e-01, -6.8163e-01,  2.2314e-01,  4.0575e-01],\n",
       "                      [-3.1799e-01,  2.0404e-01, -2.1200e-01,  1.5336e-01],\n",
       "                      [-3.5667e-02, -9.3842e-02, -3.1250e-01, -2.4350e-01],\n",
       "                      [-6.5084e-01,  3.4865e-01, -4.0996e-01,  1.7189e-01],\n",
       "                      [-4.7956e-01, -4.6615e-01, -5.2109e-01,  3.7528e-01],\n",
       "                      [-5.6494e-01,  1.3866e-02, -3.9123e-01,  3.0721e-01],\n",
       "                      [-2.0951e-01, -2.7914e-02, -2.0917e-01, -1.2089e-01],\n",
       "                      [-2.8942e-01,  1.2080e+00,  1.6737e+00,  1.2051e+00],\n",
       "                      [-3.7693e-01,  4.5528e-01,  1.0988e+00,  1.0558e+00],\n",
       "                      [ 3.4480e-01,  4.1598e-01,  1.2684e+00,  1.0201e+00],\n",
       "                      [ 1.1129e+00,  2.6467e-01, -2.7209e-01, -4.9529e-01],\n",
       "                      [-3.1893e-03,  9.4378e-01,  1.5798e+00,  1.1717e+00],\n",
       "                      [-7.9598e-01, -2.7372e-02,  6.4054e-01, -4.0441e-01],\n",
       "                      [ 2.7397e-01,  1.0259e+00,  1.2107e+00,  1.1537e+00],\n",
       "                      [-2.4057e-01,  1.1958e-01,  2.2915e-01, -3.4862e-01],\n",
       "                      [-3.1446e-01,  1.1025e-01, -5.2262e-01,  1.4562e-01],\n",
       "                      [-2.3530e-01,  3.9388e-02, -5.0188e-01,  2.6452e-01],\n",
       "                      [ 2.7002e-01, -8.3335e-01, -1.5980e+00, -1.2980e+00],\n",
       "                      [-6.7302e-01,  2.1140e-02,  1.5404e-01, -1.8334e-01],\n",
       "                      [-2.6240e-01,  1.1287e-01,  8.8685e-02, -3.2289e-01],\n",
       "                      [-4.0406e-01, -1.0605e-02,  1.4851e-01,  3.1158e-01],\n",
       "                      [-5.8624e-01, -1.2061e-01, -1.5054e-01, -3.2889e-01],\n",
       "                      [-3.4843e-01,  9.6124e-02, -5.5989e-02, -2.3070e-01],\n",
       "                      [-5.7425e-01,  4.9615e-01,  1.2588e+00,  1.1308e+00],\n",
       "                      [ 1.6450e-01, -2.9692e-01,  1.0658e-01,  1.3016e-02],\n",
       "                      [-8.3999e-01, -2.7071e-01,  3.0402e-01,  1.2438e-01],\n",
       "                      [-1.1642e-01, -4.6474e-01, -6.3127e-01, -4.1033e-01],\n",
       "                      [ 9.2673e-02, -3.9910e-01, -1.4544e+00, -7.9054e-01],\n",
       "                      [-4.1648e-02, -4.2844e-01,  4.8554e-01, -2.3150e-01],\n",
       "                      [-5.3524e-01,  2.7240e-01, -1.1931e-01, -9.6220e-02],\n",
       "                      [-5.7364e-01,  1.6177e-01,  1.5799e-01, -3.7280e-01],\n",
       "                      [ 1.3427e+00, -6.1235e-01, -9.7530e-01, -1.2538e+00],\n",
       "                      [-2.4894e-01, -2.0771e-01,  8.5673e-02,  2.5015e-01],\n",
       "                      [-3.3967e-01, -1.1911e-01, -3.7040e-01,  5.0993e-02],\n",
       "                      [ 2.3652e-01, -8.7024e-01, -1.6531e+00, -1.3554e+00]])),\n",
       "             ('qnet.layers.0.bias',\n",
       "              tensor([ 0.7378,  0.0546,  1.1766, -0.4604,  0.9112, -0.4423, -0.5334,  0.8634,\n",
       "                      -0.4978,  1.2729,  1.3056,  1.2640,  0.9269, -0.4266,  0.0112,  0.9274,\n",
       "                       1.2368, -0.5851, -0.0446,  1.4727,  0.9742,  0.8732,  1.0410,  0.9629,\n",
       "                       1.1661,  0.8841,  1.1831,  1.2840,  1.3060,  1.3164,  0.9740,  0.0071,\n",
       "                      -0.0872, -0.0416,  1.3956,  0.8692,  1.3989,  1.3362, -0.4401,  1.3659,\n",
       "                       1.3644,  1.2442,  1.0164,  0.8747,  1.2417,  1.1477,  0.0553,  1.4409,\n",
       "                       1.2602,  1.0785,  0.0873,  1.4628, -0.0127, -0.6040, -0.3594,  1.0316,\n",
       "                       1.2068, -0.7483,  0.8983,  1.2934, -0.5856,  1.2773,  0.0647, -0.5465,\n",
       "                       0.0587,  1.0712, -0.8197,  0.9858, -0.5448, -0.6296,  1.2069,  1.5053,\n",
       "                      -0.7534,  1.3628,  1.2294,  1.3876,  1.2588,  0.9216,  1.4061,  0.9792,\n",
       "                       0.9379,  1.3809,  1.1011, -0.3219, -0.8406,  1.1805,  1.1208,  1.3666,\n",
       "                       1.0128, -0.0068,  1.2776,  0.8656,  1.4669, -0.5826,  1.3039,  1.1209,\n",
       "                       1.2781,  0.9612,  1.3775,  0.9801,  0.0163,  0.0692, -0.0522,  0.0991,\n",
       "                      -0.0473,  1.0516,  0.0096,  1.4720,  1.1448,  1.1630, -0.5266,  0.8607,\n",
       "                       1.2317,  1.5202,  1.0862,  1.0173,  0.0603,  1.3229,  1.0049, -0.6986,\n",
       "                      -0.4329,  1.0833,  1.1155,  1.2037, -0.5903,  1.3704,  1.0396, -0.4826])),\n",
       "             ('qnet.layers.2.weight',\n",
       "              tensor([[ 1.3860e+00, -1.3790e+00,  5.7096e-01, -8.1564e-01,  6.2340e-01,\n",
       "                       -5.0745e-01,  1.4263e-02,  5.9510e-01, -5.9435e-02,  6.8451e-01,\n",
       "                        5.4747e-01,  6.8321e-01,  7.3860e-01, -4.5825e-01, -1.1067e+00,\n",
       "                        1.0127e+00,  8.0616e-01, -7.3618e-01, -9.5996e-01,  1.0537e+00,\n",
       "                        1.1198e+00,  1.0737e+00,  6.5299e-01,  1.0365e+00,  6.7233e-01,\n",
       "                        9.6557e-01,  7.1294e-01,  7.3032e-01,  8.1165e-01,  1.0243e+00,\n",
       "                        9.8215e-01, -1.1416e+00,  6.7673e-01, -1.1482e+00,  6.0873e-01,\n",
       "                        8.1018e-01,  7.3427e-01,  7.6172e-01, -2.6211e-01,  8.3938e-01,\n",
       "                        9.7418e-01,  1.1096e+00,  7.2483e-01,  7.8543e-01,  1.3240e+00,\n",
       "                        7.4718e-01, -1.2621e+00,  9.1667e-01,  6.7280e-01,  5.3591e-01,\n",
       "                       -1.2153e+00,  6.0466e-01, -1.1896e+00, -2.2558e-01, -1.1661e-02,\n",
       "                        5.1295e-01,  8.6252e-01, -8.4937e-01,  4.8414e-01,  1.4843e+00,\n",
       "                       -6.2050e-01,  6.9997e-01, -7.9988e-01, -5.5964e-01, -1.1150e+00,\n",
       "                        8.0650e-01, -3.9425e-01,  4.2672e-01, -4.8260e-01, -7.7935e-01,\n",
       "                        7.5050e-01,  5.9605e-01, -6.1141e-01,  7.0106e-01,  6.1766e-01,\n",
       "                        7.2403e-01,  1.3533e+00,  9.8384e-01,  4.7999e-01,  5.8118e-01,\n",
       "                        8.9448e-01,  8.2663e-01,  6.4396e-01, -2.2048e-02, -1.5460e-01,\n",
       "                        6.9645e-01,  7.3425e-01,  5.7860e-01,  4.6932e-01, -1.2301e+00,\n",
       "                        6.9912e-01,  4.9279e-01,  7.5262e-01, -4.8752e-01,  8.1556e-01,\n",
       "                        9.2037e-01,  6.7793e-01,  4.3833e-01,  8.0830e-01,  9.6692e-01,\n",
       "                       -1.2949e+00, -9.7731e-01, -6.0263e-01, -8.2316e-01, -1.0683e+00,\n",
       "                        4.7165e-01, -1.2782e+00,  7.0455e-01,  1.1478e+00,  1.0871e+00,\n",
       "                       -5.8919e-01,  9.2931e-01,  9.5360e-01,  7.6484e-01,  6.6034e-01,\n",
       "                        8.9489e-01, -8.0737e-01,  9.6030e-01,  6.6418e-01, -5.6056e-01,\n",
       "                       -6.6783e-01,  7.7194e-01,  1.0466e+00,  6.4335e-01, -5.2095e-01,\n",
       "                        7.5042e-01,  7.9174e-01, -3.9518e-01],\n",
       "                      [ 9.7960e-01, -9.3694e-01,  8.7137e-01, -1.3153e+00,  1.0558e+00,\n",
       "                       -8.3740e-01,  5.0714e-02,  8.4275e-01, -1.1090e-02,  7.2454e-01,\n",
       "                        7.8832e-01,  7.0171e-01,  7.9275e-01, -8.3202e-01, -1.1288e+00,\n",
       "                        8.0429e-01,  8.7229e-01, -1.1283e+00, -9.8146e-01,  8.2898e-01,\n",
       "                        9.5763e-01,  9.6011e-01,  7.0120e-01,  8.9828e-01,  1.0214e+00,\n",
       "                        9.1115e-01,  8.1376e-01,  7.4270e-01,  7.8610e-01,  8.0761e-01,\n",
       "                        8.2504e-01, -9.5887e-01, -8.9500e-01, -1.0108e+00,  8.0594e-01,\n",
       "                        1.1099e+00,  7.2113e-01,  8.9120e-01, -4.0647e-01,  8.5824e-01,\n",
       "                        8.2651e-01,  7.8088e-01,  7.0098e-01,  6.3209e-01,  1.0074e+00,\n",
       "                        8.3524e-01, -9.1737e-01,  8.3043e-01,  7.2946e-01,  7.7805e-01,\n",
       "                       -7.9350e-01,  7.8440e-01, -1.0065e+00, -1.2278e+00,  6.2125e-04,\n",
       "                        6.6822e-01,  7.1189e-01, -1.3159e+00,  7.8638e-01,  1.0600e+00,\n",
       "                       -1.4439e+00,  7.4990e-01, -1.7138e+00, -1.4214e+00, -1.0067e+00,\n",
       "                        9.8058e-01, -6.6391e-01,  6.4611e-01, -1.4218e+00, -1.3757e+00,\n",
       "                        8.0558e-01,  7.9960e-01, -1.3164e+00,  1.0415e+00,  8.1608e-01,\n",
       "                        8.8585e-01,  1.0274e+00,  7.5356e-01,  8.3229e-01,  7.1598e-01,\n",
       "                        9.0448e-01,  8.4035e-01,  6.8376e-01, -6.7099e-02, -4.2736e-01,\n",
       "                        7.5832e-01,  1.1972e+00,  7.8573e-01,  8.5985e-01, -1.0120e+00,\n",
       "                        7.4370e-01,  1.0229e+00,  7.7859e-01, -8.9449e-01,  7.9640e-01,\n",
       "                        9.1418e-01,  7.3484e-01,  8.2465e-01,  8.6862e-01,  8.2474e-01,\n",
       "                       -1.0458e+00, -7.3890e-01, -9.1471e-01, -1.3442e+00, -1.0407e+00,\n",
       "                        8.0035e-01, -1.0342e+00,  8.4410e-01,  8.0459e-01,  8.2888e-01,\n",
       "                       -1.5108e+00,  9.8939e-01,  7.8395e-01,  7.3060e-01,  9.7978e-01,\n",
       "                        7.3802e-01, -4.9660e-01,  6.3854e-01,  1.1354e+00, -4.6150e-01,\n",
       "                       -1.3303e+00,  8.9939e-01,  7.9274e-01,  7.6327e-01, -1.4294e+00,\n",
       "                        8.5759e-01,  7.9556e-01, -1.3028e+00]])),\n",
       "             ('qnet.layers.2.bias', tensor([0.6992, 0.6193]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 불러오기\n",
    "\n",
    "`nn.Module`의 `state_dict()`은 모델의 파라미터 값 및 버퍼의 값들만을 저장합니다. `state_dict()` 자체에는 모델의 구조 및 연산 과정등을 저장하지 않습니다. 따라서 모델을 불러올 때는 저장한 모델과 같은 구조를 가진 모델을 만들고, 그 모델에 디스크에서 불러온 `state_dict()` 를 덮어씌우는 형태로 구현됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnet2 = MLP(input_dim=s_dim,\n",
    "            output_dim=a_dim,\n",
    "            num_neurons=[128],\n",
    "            hidden_act='ReLU',\n",
    "            out_act='Identity')\n",
    "\n",
    "agent2 = NaiveDQN(state_dim=s_dim,\n",
    "                  action_dim=a_dim,\n",
    "                  qnet=qnet,\n",
    "                  lr=1e-4,\n",
    "                  gamma=1.0,\n",
    "                  epsilon=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent2.load_state_dict(torch.load(SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('epsilon', tensor([5.2495e-05])),\n",
       "             ('qnet.layers.0.weight',\n",
       "              tensor([[-2.5274e-01, -1.0068e-01, -6.6648e-01, -1.4273e-01],\n",
       "                      [ 6.3685e-03,  1.1984e+00,  1.4588e+00,  1.2057e+00],\n",
       "                      [-7.9896e-01,  1.5624e-01,  5.4470e-01, -1.6938e-01],\n",
       "                      [-4.4573e-02, -3.0556e-01, -1.8010e+00, -5.5101e-01],\n",
       "                      [-6.3286e-01, -2.2097e-01,  1.1782e-01, -3.8638e-01],\n",
       "                      [-7.1657e-01, -3.3559e-01,  6.3424e-01,  5.2899e-01],\n",
       "                      [-2.9158e-01,  1.0486e-01,  4.6626e-01,  4.8948e-03],\n",
       "                      [-7.7268e-01,  1.2427e-01,  3.9761e-01, -4.3084e-01],\n",
       "                      [ 4.8953e-01, -3.7138e-01,  4.8951e-01, -1.5558e-01],\n",
       "                      [-3.5489e-01,  1.9541e-01,  5.6598e-01, -3.2747e-01],\n",
       "                      [-2.5850e-01,  2.2271e-02, -1.2181e-01, -1.8363e-01],\n",
       "                      [-6.6856e-01,  4.2945e-01, -4.1947e-01,  1.1752e-02],\n",
       "                      [-8.8613e-01,  2.4342e-01,  2.7556e-01, -1.5106e-01],\n",
       "                      [-1.1327e+00, -4.9109e-01,  4.4440e-01,  1.1181e-01],\n",
       "                      [-2.1302e-01,  7.9746e-01,  1.7114e+00,  1.1340e+00],\n",
       "                      [-4.1125e-02, -2.3066e-01, -1.3572e-01, -4.2071e-02],\n",
       "                      [-1.6432e-01, -3.4914e-01,  3.6136e-01, -2.6125e-01],\n",
       "                      [ 5.0416e-01, -4.8463e-01, -1.2442e+00, -7.7392e-01],\n",
       "                      [ 8.7478e-02,  7.1535e-01,  1.7291e+00,  1.0625e+00],\n",
       "                      [-2.5386e-01,  1.8020e-01, -3.8648e-01,  3.4629e-01],\n",
       "                      [-6.4514e-01,  1.5716e-01, -4.8180e-02,  1.4021e-01],\n",
       "                      [-4.5624e-01,  7.9707e-03,  4.0237e-01, -1.2257e-01],\n",
       "                      [-5.0100e-01,  2.2681e-01, -1.2583e-01, -1.2320e-01],\n",
       "                      [-2.5099e-01, -1.1872e-02, -1.1767e-01, -8.6048e-02],\n",
       "                      [-6.2496e-01, -2.0600e-01, -1.0459e-01, -4.9232e-01],\n",
       "                      [-4.6662e-01,  3.2273e-02,  4.8839e-01, -1.7274e-01],\n",
       "                      [-1.5707e-01, -3.0799e-01,  3.3868e-01,  2.0816e-01],\n",
       "                      [-2.4717e-01,  1.4629e-01, -9.2950e-02, -4.0518e-01],\n",
       "                      [-2.4071e-01, -1.4769e-01, -2.1676e-01,  1.0029e-01],\n",
       "                      [ 5.7891e-02, -1.7909e-01,  1.8628e-01, -1.7098e-02],\n",
       "                      [-3.5343e-01,  7.6027e-02,  2.4733e-03, -2.5116e-01],\n",
       "                      [ 3.7576e-01,  9.8034e-01,  1.2587e+00,  1.1095e+00],\n",
       "                      [ 6.3896e-01, -1.0383e+00, -1.9851e+00, -2.0152e+00],\n",
       "                      [ 3.5571e-01,  8.7373e-01,  1.1626e+00,  1.2993e+00],\n",
       "                      [-5.8215e-01, -1.9586e-01,  2.2537e-02,  3.5296e-01],\n",
       "                      [-3.7591e-01, -3.1101e-01, -5.7840e-02, -3.6117e-01],\n",
       "                      [-5.0472e-01,  1.6397e-01,  1.2695e-01, -1.5062e-01],\n",
       "                      [-7.8357e-01, -1.7197e-01, -2.6605e-02,  9.7357e-02],\n",
       "                      [-5.8209e-01, -3.9985e-01,  4.6935e-01,  2.6984e-01],\n",
       "                      [-1.3666e-01, -1.0798e-01, -8.0046e-02,  1.8770e-01],\n",
       "                      [-6.0844e-01,  4.0469e-01,  1.6820e-02,  2.8492e-01],\n",
       "                      [-2.2080e-01,  6.7309e-02, -4.2135e-01,  1.2730e-01],\n",
       "                      [-6.8360e-01,  3.3381e-01, -4.2332e-01, -1.6059e-01],\n",
       "                      [-4.9568e-02, -2.2798e-01, -6.2120e-01,  1.2824e-01],\n",
       "                      [-2.8179e-01,  6.4591e-02,  1.9266e-01,  1.6586e-01],\n",
       "                      [-6.5832e-01,  3.1662e-01,  2.9850e-02, -1.6049e-01],\n",
       "                      [ 2.1221e-02,  1.0706e+00,  1.0961e+00,  1.0742e+00],\n",
       "                      [-6.9440e-02, -1.3853e-01, -1.0041e-02,  2.4366e-01],\n",
       "                      [-7.8534e-01,  4.1054e-01, -3.6331e-01, -2.3822e-01],\n",
       "                      [-5.1292e-01, -3.2918e-01, -4.2660e-01,  2.4826e-01],\n",
       "                      [ 3.9943e-01,  9.3431e-01,  1.6921e+00,  8.9760e-01],\n",
       "                      [-6.9400e-01,  3.3940e-01,  2.1287e-01, -2.4512e-01],\n",
       "                      [ 2.5977e-01,  1.0471e+00,  1.4151e+00,  1.1998e+00],\n",
       "                      [ 1.0721e+00, -6.1333e-01, -9.8405e-01, -1.3860e+00],\n",
       "                      [ 1.3817e-01, -1.7452e-01, -3.3949e-01, -1.5293e-03],\n",
       "                      [-6.6154e-01,  3.0565e-01, -1.3869e-01, -1.4089e-01],\n",
       "                      [-3.2425e-01,  2.2958e-02,  2.1984e-01,  1.8816e-01],\n",
       "                      [ 5.4639e-01, -6.6717e-01, -1.5453e+00, -1.1070e+00],\n",
       "                      [-5.9495e-01, -2.8925e-01, -4.4095e-01,  2.0557e-01],\n",
       "                      [-6.1370e-01,  3.1933e-01,  2.0745e-01,  2.3702e-01],\n",
       "                      [ 9.7572e-01, -5.0899e-01, -1.3273e+00, -1.0698e+00],\n",
       "                      [-6.8213e-01,  4.3697e-01, -4.8022e-02, -1.9608e-01],\n",
       "                      [ 1.1545e+00,  3.9999e-01, -1.0704e+00, -4.4756e-01],\n",
       "                      [ 3.0458e-01, -9.5902e-01, -1.4184e+00, -1.3538e+00],\n",
       "                      [-1.3114e-03,  1.1867e+00,  1.1004e+00,  9.5316e-01],\n",
       "                      [-5.0881e-01, -2.9716e-01,  4.3324e-01, -6.0420e-02],\n",
       "                      [-5.6298e-01, -5.6382e-01, -4.5171e-01, -6.1560e-01],\n",
       "                      [-5.9926e-01,  8.1733e-02,  2.4011e-02, -1.5259e-01],\n",
       "                      [ 1.2203e+00, -5.0664e-01, -1.2283e+00, -1.0794e+00],\n",
       "                      [ 2.7576e-01, -8.0613e-01, -1.8308e+00, -1.0563e+00],\n",
       "                      [-2.7118e-01, -7.6258e-02,  9.9550e-02, -6.0600e-02],\n",
       "                      [-4.6010e-01,  8.2420e-02,  3.0057e-01, -4.2645e-01],\n",
       "                      [ 1.2328e+00, -8.0393e-01, -1.1888e+00, -1.3958e+00],\n",
       "                      [-6.5195e-01, -4.1752e-01,  3.8276e-01, -9.8267e-02],\n",
       "                      [-7.2884e-01, -5.9799e-02, -3.6481e-01, -2.5915e-01],\n",
       "                      [-8.6933e-01,  2.0574e-01,  4.3064e-01,  1.2519e-01],\n",
       "                      [-4.3893e-01,  1.8752e-01,  2.5586e-01,  2.2808e-01],\n",
       "                      [-3.0933e-01, -3.1249e-02,  1.3667e-01, -9.2543e-02],\n",
       "                      [-9.1448e-01,  1.1019e-01, -2.1288e-01, -2.8973e-01],\n",
       "                      [-5.4210e-01,  1.8134e-01,  3.2955e-01, -3.1581e-01],\n",
       "                      [-6.8018e-01,  1.6352e-01,  3.5516e-01, -2.2068e-01],\n",
       "                      [-5.7393e-02, -2.3605e-01, -2.9240e-01,  2.4430e-01],\n",
       "                      [-2.9867e-01,  9.8007e-02,  4.1597e-02, -4.0590e-01],\n",
       "                      [-1.8992e-01,  2.0997e-01, -3.2839e-02,  6.4192e-02],\n",
       "                      [-7.7801e-01, -5.3990e-01, -4.6958e-01, -4.2892e-01],\n",
       "                      [-7.7751e-01,  1.9776e-01,  2.7270e-01, -8.9519e-02],\n",
       "                      [-5.1281e-01, -3.1992e-01, -1.8180e-02, -4.0125e-01],\n",
       "                      [-8.2186e-01,  4.0946e-01, -3.3423e-01,  5.1428e-02],\n",
       "                      [-9.9534e-01,  1.0573e-01,  7.0803e-01, -4.2278e-01],\n",
       "                      [ 3.4937e-01,  6.7653e-01,  2.0432e+00,  9.9519e-01],\n",
       "                      [-7.4545e-01,  5.0722e-01, -4.8586e-01,  7.3090e-02],\n",
       "                      [-1.0733e-01, -6.1685e-01, -5.2684e-01,  2.6111e-01],\n",
       "                      [-4.2064e-01, -8.0237e-02, -9.9222e-02,  2.9613e-01],\n",
       "                      [-9.3641e-01, -6.8163e-01,  2.2314e-01,  4.0575e-01],\n",
       "                      [-3.1799e-01,  2.0404e-01, -2.1200e-01,  1.5336e-01],\n",
       "                      [-3.5667e-02, -9.3842e-02, -3.1250e-01, -2.4350e-01],\n",
       "                      [-6.5084e-01,  3.4865e-01, -4.0996e-01,  1.7189e-01],\n",
       "                      [-4.7956e-01, -4.6615e-01, -5.2109e-01,  3.7528e-01],\n",
       "                      [-5.6494e-01,  1.3866e-02, -3.9123e-01,  3.0721e-01],\n",
       "                      [-2.0951e-01, -2.7914e-02, -2.0917e-01, -1.2089e-01],\n",
       "                      [-2.8942e-01,  1.2080e+00,  1.6737e+00,  1.2051e+00],\n",
       "                      [-3.7693e-01,  4.5528e-01,  1.0988e+00,  1.0558e+00],\n",
       "                      [ 3.4480e-01,  4.1598e-01,  1.2684e+00,  1.0201e+00],\n",
       "                      [ 1.1129e+00,  2.6467e-01, -2.7209e-01, -4.9529e-01],\n",
       "                      [-3.1893e-03,  9.4378e-01,  1.5798e+00,  1.1717e+00],\n",
       "                      [-7.9598e-01, -2.7372e-02,  6.4054e-01, -4.0441e-01],\n",
       "                      [ 2.7397e-01,  1.0259e+00,  1.2107e+00,  1.1537e+00],\n",
       "                      [-2.4057e-01,  1.1958e-01,  2.2915e-01, -3.4862e-01],\n",
       "                      [-3.1446e-01,  1.1025e-01, -5.2262e-01,  1.4562e-01],\n",
       "                      [-2.3530e-01,  3.9388e-02, -5.0188e-01,  2.6452e-01],\n",
       "                      [ 2.7002e-01, -8.3335e-01, -1.5980e+00, -1.2980e+00],\n",
       "                      [-6.7302e-01,  2.1140e-02,  1.5404e-01, -1.8334e-01],\n",
       "                      [-2.6240e-01,  1.1287e-01,  8.8685e-02, -3.2289e-01],\n",
       "                      [-4.0406e-01, -1.0605e-02,  1.4851e-01,  3.1158e-01],\n",
       "                      [-5.8624e-01, -1.2061e-01, -1.5054e-01, -3.2889e-01],\n",
       "                      [-3.4843e-01,  9.6124e-02, -5.5989e-02, -2.3070e-01],\n",
       "                      [-5.7425e-01,  4.9615e-01,  1.2588e+00,  1.1308e+00],\n",
       "                      [ 1.6450e-01, -2.9692e-01,  1.0658e-01,  1.3016e-02],\n",
       "                      [-8.3999e-01, -2.7071e-01,  3.0402e-01,  1.2438e-01],\n",
       "                      [-1.1642e-01, -4.6474e-01, -6.3127e-01, -4.1033e-01],\n",
       "                      [ 9.2673e-02, -3.9910e-01, -1.4544e+00, -7.9054e-01],\n",
       "                      [-4.1648e-02, -4.2844e-01,  4.8554e-01, -2.3150e-01],\n",
       "                      [-5.3524e-01,  2.7240e-01, -1.1931e-01, -9.6220e-02],\n",
       "                      [-5.7364e-01,  1.6177e-01,  1.5799e-01, -3.7280e-01],\n",
       "                      [ 1.3427e+00, -6.1235e-01, -9.7530e-01, -1.2538e+00],\n",
       "                      [-2.4894e-01, -2.0771e-01,  8.5673e-02,  2.5015e-01],\n",
       "                      [-3.3967e-01, -1.1911e-01, -3.7040e-01,  5.0993e-02],\n",
       "                      [ 2.3652e-01, -8.7024e-01, -1.6531e+00, -1.3554e+00]])),\n",
       "             ('qnet.layers.0.bias',\n",
       "              tensor([ 0.7378,  0.0546,  1.1766, -0.4604,  0.9112, -0.4423, -0.5334,  0.8634,\n",
       "                      -0.4978,  1.2729,  1.3056,  1.2640,  0.9269, -0.4266,  0.0112,  0.9274,\n",
       "                       1.2368, -0.5851, -0.0446,  1.4727,  0.9742,  0.8732,  1.0410,  0.9629,\n",
       "                       1.1661,  0.8841,  1.1831,  1.2840,  1.3060,  1.3164,  0.9740,  0.0071,\n",
       "                      -0.0872, -0.0416,  1.3956,  0.8692,  1.3989,  1.3362, -0.4401,  1.3659,\n",
       "                       1.3644,  1.2442,  1.0164,  0.8747,  1.2417,  1.1477,  0.0553,  1.4409,\n",
       "                       1.2602,  1.0785,  0.0873,  1.4628, -0.0127, -0.6040, -0.3594,  1.0316,\n",
       "                       1.2068, -0.7483,  0.8983,  1.2934, -0.5856,  1.2773,  0.0647, -0.5465,\n",
       "                       0.0587,  1.0712, -0.8197,  0.9858, -0.5448, -0.6296,  1.2069,  1.5053,\n",
       "                      -0.7534,  1.3628,  1.2294,  1.3876,  1.2588,  0.9216,  1.4061,  0.9792,\n",
       "                       0.9379,  1.3809,  1.1011, -0.3219, -0.8406,  1.1805,  1.1208,  1.3666,\n",
       "                       1.0128, -0.0068,  1.2776,  0.8656,  1.4669, -0.5826,  1.3039,  1.1209,\n",
       "                       1.2781,  0.9612,  1.3775,  0.9801,  0.0163,  0.0692, -0.0522,  0.0991,\n",
       "                      -0.0473,  1.0516,  0.0096,  1.4720,  1.1448,  1.1630, -0.5266,  0.8607,\n",
       "                       1.2317,  1.5202,  1.0862,  1.0173,  0.0603,  1.3229,  1.0049, -0.6986,\n",
       "                      -0.4329,  1.0833,  1.1155,  1.2037, -0.5903,  1.3704,  1.0396, -0.4826])),\n",
       "             ('qnet.layers.2.weight',\n",
       "              tensor([[ 1.3860e+00, -1.3790e+00,  5.7096e-01, -8.1564e-01,  6.2340e-01,\n",
       "                       -5.0745e-01,  1.4263e-02,  5.9510e-01, -5.9435e-02,  6.8451e-01,\n",
       "                        5.4747e-01,  6.8321e-01,  7.3860e-01, -4.5825e-01, -1.1067e+00,\n",
       "                        1.0127e+00,  8.0616e-01, -7.3618e-01, -9.5996e-01,  1.0537e+00,\n",
       "                        1.1198e+00,  1.0737e+00,  6.5299e-01,  1.0365e+00,  6.7233e-01,\n",
       "                        9.6557e-01,  7.1294e-01,  7.3032e-01,  8.1165e-01,  1.0243e+00,\n",
       "                        9.8215e-01, -1.1416e+00,  6.7673e-01, -1.1482e+00,  6.0873e-01,\n",
       "                        8.1018e-01,  7.3427e-01,  7.6172e-01, -2.6211e-01,  8.3938e-01,\n",
       "                        9.7418e-01,  1.1096e+00,  7.2483e-01,  7.8543e-01,  1.3240e+00,\n",
       "                        7.4718e-01, -1.2621e+00,  9.1667e-01,  6.7280e-01,  5.3591e-01,\n",
       "                       -1.2153e+00,  6.0466e-01, -1.1896e+00, -2.2558e-01, -1.1661e-02,\n",
       "                        5.1295e-01,  8.6252e-01, -8.4937e-01,  4.8414e-01,  1.4843e+00,\n",
       "                       -6.2050e-01,  6.9997e-01, -7.9988e-01, -5.5964e-01, -1.1150e+00,\n",
       "                        8.0650e-01, -3.9425e-01,  4.2672e-01, -4.8260e-01, -7.7935e-01,\n",
       "                        7.5050e-01,  5.9605e-01, -6.1141e-01,  7.0106e-01,  6.1766e-01,\n",
       "                        7.2403e-01,  1.3533e+00,  9.8384e-01,  4.7999e-01,  5.8118e-01,\n",
       "                        8.9448e-01,  8.2663e-01,  6.4396e-01, -2.2048e-02, -1.5460e-01,\n",
       "                        6.9645e-01,  7.3425e-01,  5.7860e-01,  4.6932e-01, -1.2301e+00,\n",
       "                        6.9912e-01,  4.9279e-01,  7.5262e-01, -4.8752e-01,  8.1556e-01,\n",
       "                        9.2037e-01,  6.7793e-01,  4.3833e-01,  8.0830e-01,  9.6692e-01,\n",
       "                       -1.2949e+00, -9.7731e-01, -6.0263e-01, -8.2316e-01, -1.0683e+00,\n",
       "                        4.7165e-01, -1.2782e+00,  7.0455e-01,  1.1478e+00,  1.0871e+00,\n",
       "                       -5.8919e-01,  9.2931e-01,  9.5360e-01,  7.6484e-01,  6.6034e-01,\n",
       "                        8.9489e-01, -8.0737e-01,  9.6030e-01,  6.6418e-01, -5.6056e-01,\n",
       "                       -6.6783e-01,  7.7194e-01,  1.0466e+00,  6.4335e-01, -5.2095e-01,\n",
       "                        7.5042e-01,  7.9174e-01, -3.9518e-01],\n",
       "                      [ 9.7960e-01, -9.3694e-01,  8.7137e-01, -1.3153e+00,  1.0558e+00,\n",
       "                       -8.3740e-01,  5.0714e-02,  8.4275e-01, -1.1090e-02,  7.2454e-01,\n",
       "                        7.8832e-01,  7.0171e-01,  7.9275e-01, -8.3202e-01, -1.1288e+00,\n",
       "                        8.0429e-01,  8.7229e-01, -1.1283e+00, -9.8146e-01,  8.2898e-01,\n",
       "                        9.5763e-01,  9.6011e-01,  7.0120e-01,  8.9828e-01,  1.0214e+00,\n",
       "                        9.1115e-01,  8.1376e-01,  7.4270e-01,  7.8610e-01,  8.0761e-01,\n",
       "                        8.2504e-01, -9.5887e-01, -8.9500e-01, -1.0108e+00,  8.0594e-01,\n",
       "                        1.1099e+00,  7.2113e-01,  8.9120e-01, -4.0647e-01,  8.5824e-01,\n",
       "                        8.2651e-01,  7.8088e-01,  7.0098e-01,  6.3209e-01,  1.0074e+00,\n",
       "                        8.3524e-01, -9.1737e-01,  8.3043e-01,  7.2946e-01,  7.7805e-01,\n",
       "                       -7.9350e-01,  7.8440e-01, -1.0065e+00, -1.2278e+00,  6.2125e-04,\n",
       "                        6.6822e-01,  7.1189e-01, -1.3159e+00,  7.8638e-01,  1.0600e+00,\n",
       "                       -1.4439e+00,  7.4990e-01, -1.7138e+00, -1.4214e+00, -1.0067e+00,\n",
       "                        9.8058e-01, -6.6391e-01,  6.4611e-01, -1.4218e+00, -1.3757e+00,\n",
       "                        8.0558e-01,  7.9960e-01, -1.3164e+00,  1.0415e+00,  8.1608e-01,\n",
       "                        8.8585e-01,  1.0274e+00,  7.5356e-01,  8.3229e-01,  7.1598e-01,\n",
       "                        9.0448e-01,  8.4035e-01,  6.8376e-01, -6.7099e-02, -4.2736e-01,\n",
       "                        7.5832e-01,  1.1972e+00,  7.8573e-01,  8.5985e-01, -1.0120e+00,\n",
       "                        7.4370e-01,  1.0229e+00,  7.7859e-01, -8.9449e-01,  7.9640e-01,\n",
       "                        9.1418e-01,  7.3484e-01,  8.2465e-01,  8.6862e-01,  8.2474e-01,\n",
       "                       -1.0458e+00, -7.3890e-01, -9.1471e-01, -1.3442e+00, -1.0407e+00,\n",
       "                        8.0035e-01, -1.0342e+00,  8.4410e-01,  8.0459e-01,  8.2888e-01,\n",
       "                       -1.5108e+00,  9.8939e-01,  7.8395e-01,  7.3060e-01,  9.7978e-01,\n",
       "                        7.3802e-01, -4.9660e-01,  6.3854e-01,  1.1354e+00, -4.6150e-01,\n",
       "                       -1.3303e+00,  8.9939e-01,  7.9274e-01,  7.6327e-01, -1.4294e+00,\n",
       "                        8.5759e-01,  7.9556e-01, -1.3028e+00]])),\n",
       "             ('qnet.layers.2.bias', tensor([0.6992, 0.6193]))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent2.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
